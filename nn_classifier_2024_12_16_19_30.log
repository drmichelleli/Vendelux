2024-12-16 19:30:45,816 - INFO - input data size: 1569
2024-12-16 19:30:45,817 - INFO - Neural network classifier on the whole data set 
2024-12-16 19:30:45,821 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
2024-12-16 19:31:40,653 - INFO - Epoch [1/30], Loss: 0.7202, Val Loss: 0.6573
2024-12-16 19:31:40,667 - INFO - Epoch [2/30], Loss: 0.6516, Val Loss: 0.6073
2024-12-16 19:31:40,679 - INFO - Epoch [3/30], Loss: 0.6073, Val Loss: 0.5651
2024-12-16 19:31:40,691 - INFO - Epoch [4/30], Loss: 0.5610, Val Loss: 0.5301
2024-12-16 19:31:40,703 - INFO - Epoch [5/30], Loss: 0.5316, Val Loss: 0.5027
2024-12-16 19:31:40,714 - INFO - Epoch [6/30], Loss: 0.5011, Val Loss: 0.4819
2024-12-16 19:31:40,726 - INFO - Epoch [7/30], Loss: 0.4798, Val Loss: 0.4670
2024-12-16 19:31:40,739 - INFO - Epoch [8/30], Loss: 0.4574, Val Loss: 0.4560
2024-12-16 19:31:40,751 - INFO - Epoch [9/30], Loss: 0.4536, Val Loss: 0.4475
2024-12-16 19:31:40,763 - INFO - Epoch [10/30], Loss: 0.4435, Val Loss: 0.4404
2024-12-16 19:31:40,775 - INFO - Epoch [11/30], Loss: 0.4285, Val Loss: 0.4347
2024-12-16 19:31:40,788 - INFO - Epoch [12/30], Loss: 0.4165, Val Loss: 0.4296
2024-12-16 19:31:40,800 - INFO - Epoch [13/30], Loss: 0.4092, Val Loss: 0.4253
2024-12-16 19:31:40,812 - INFO - Epoch [14/30], Loss: 0.4022, Val Loss: 0.4211
2024-12-16 19:31:40,824 - INFO - Epoch [15/30], Loss: 0.3934, Val Loss: 0.4170
2024-12-16 19:31:40,836 - INFO - Epoch [16/30], Loss: 0.3873, Val Loss: 0.4128
2024-12-16 19:31:40,848 - INFO - Epoch [17/30], Loss: 0.3834, Val Loss: 0.4084
2024-12-16 19:31:40,860 - INFO - Epoch [18/30], Loss: 0.3727, Val Loss: 0.4039
2024-12-16 19:31:40,872 - INFO - Epoch [19/30], Loss: 0.3635, Val Loss: 0.3996
2024-12-16 19:31:40,884 - INFO - Epoch [20/30], Loss: 0.3544, Val Loss: 0.3957
2024-12-16 19:31:40,896 - INFO - Epoch [21/30], Loss: 0.3466, Val Loss: 0.3925
2024-12-16 19:31:40,908 - INFO - Epoch [22/30], Loss: 0.3417, Val Loss: 0.3901
2024-12-16 19:31:40,921 - INFO - Epoch [23/30], Loss: 0.3390, Val Loss: 0.3886
2024-12-16 19:31:40,932 - INFO - Epoch [24/30], Loss: 0.3297, Val Loss: 0.3877
2024-12-16 19:31:40,944 - INFO - Epoch [25/30], Loss: 0.3210, Val Loss: 0.3874
2024-12-16 19:31:40,959 - INFO - Epoch [26/30], Loss: 0.3191, Val Loss: 0.3877
2024-12-16 19:31:40,975 - INFO - Epoch [27/30], Loss: 0.3094, Val Loss: 0.3882
2024-12-16 19:31:40,990 - INFO - Epoch [28/30], Loss: 0.3027, Val Loss: 0.3891
2024-12-16 19:31:41,006 - INFO - Epoch [29/30], Loss: 0.2962, Val Loss: 0.3902
2024-12-16 19:31:41,021 - INFO - Epoch [30/30], Loss: 0.2870, Val Loss: 0.3917
2024-12-16 19:31:41,022 - INFO - Early stopping!
2024-12-16 19:31:41,028 - INFO - Accuracy: 0.8089
2024-12-16 19:31:41,037 - INFO - Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.89      0.86       213
           1       0.74      0.63      0.68       101

    accuracy                           0.81       314
   macro avg       0.79      0.76      0.77       314
weighted avg       0.80      0.81      0.80       314

2024-12-16 19:31:41,039 - INFO - Training set size: 1255
2024-12-16 19:31:41,039 - INFO - Test set size: 314
2024-12-16 19:31:41,040 - INFO - Finished successfully and it took 0.9203709833333333 minutes
2024-12-16 19:31:41,065 - INFO - Neural network classifier on the filtered data set 
2024-12-16 19:31:41,074 - INFO - filtered data size: 859
2024-12-16 19:31:41,077 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
2024-12-16 19:32:10,901 - INFO - Epoch [1/30], Loss: 0.7056, Val Loss: 0.6331
2024-12-16 19:32:10,909 - INFO - Epoch [2/30], Loss: 0.6335, Val Loss: 0.5775
2024-12-16 19:32:10,919 - INFO - Epoch [3/30], Loss: 0.5806, Val Loss: 0.5218
2024-12-16 19:32:10,928 - INFO - Epoch [4/30], Loss: 0.5243, Val Loss: 0.4645
2024-12-16 19:32:10,938 - INFO - Epoch [5/30], Loss: 0.4679, Val Loss: 0.4086
2024-12-16 19:32:10,955 - INFO - Epoch [6/30], Loss: 0.4161, Val Loss: 0.3580
2024-12-16 19:32:10,964 - INFO - Epoch [7/30], Loss: 0.3587, Val Loss: 0.3154
2024-12-16 19:32:10,974 - INFO - Epoch [8/30], Loss: 0.3079, Val Loss: 0.2824
2024-12-16 19:32:10,983 - INFO - Epoch [9/30], Loss: 0.2746, Val Loss: 0.2582
2024-12-16 19:32:10,990 - INFO - Epoch [10/30], Loss: 0.2536, Val Loss: 0.2414
2024-12-16 19:32:10,997 - INFO - Epoch [11/30], Loss: 0.2385, Val Loss: 0.2301
2024-12-16 19:32:11,004 - INFO - Epoch [12/30], Loss: 0.2156, Val Loss: 0.2227
2024-12-16 19:32:11,012 - INFO - Epoch [13/30], Loss: 0.2187, Val Loss: 0.2182
2024-12-16 19:32:11,019 - INFO - Epoch [14/30], Loss: 0.1891, Val Loss: 0.2164
2024-12-16 19:32:11,027 - INFO - Epoch [15/30], Loss: 0.2033, Val Loss: 0.2165
2024-12-16 19:32:11,038 - INFO - Epoch [16/30], Loss: 0.1765, Val Loss: 0.2184
2024-12-16 19:32:11,047 - INFO - Epoch [17/30], Loss: 0.1738, Val Loss: 0.2223
2024-12-16 19:32:11,056 - INFO - Epoch [18/30], Loss: 0.1660, Val Loss: 0.2276
2024-12-16 19:32:11,065 - INFO - Epoch [19/30], Loss: 0.1595, Val Loss: 0.2337
2024-12-16 19:32:11,065 - INFO - Early stopping!
2024-12-16 19:32:11,066 - INFO - Accuracy: 0.9360
2024-12-16 19:32:11,071 - INFO - Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.94      0.92        69
           1       0.96      0.93      0.95       103

    accuracy                           0.94       172
   macro avg       0.93      0.94      0.93       172
weighted avg       0.94      0.94      0.94       172

2024-12-16 19:32:11,073 - INFO - Training set size: 687
2024-12-16 19:32:11,073 - INFO - Test set size: 172
2024-12-16 19:32:11,073 - INFO - Finished successfully and it took 0.49997265 minutes
